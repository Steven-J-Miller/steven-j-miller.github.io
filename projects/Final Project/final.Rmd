---
title: "Section 3"
author: "Steven Miller"
date: "April 17, 2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

It's hard to display my final dataset in a single table, as it's more of a database spread across multiple tables. What I'll be doing instead is getting my data into a form that's useful for analysis of some of the questions I wanted to investigate.

The first question I want to look at was in regards to how the length of a race track impacts the fan rating of races held at the circuit. At the very minimum, I will need the circuits table from my primary dataset, and the fan ratings table.

```{r load_data_circuitratings}
circuits <- read.csv('data/circuits.csv')
fan_ratings <- read.csv('data/fan_ratings.csv')

head(circuits)
head(fan_ratings)
```

Taking a look at each table, I notice an immediate issue. There is no column that will easily join the data from one table to another. We will need additional data.

```{r more_data_circuitratings}
races = read.csv('data/races.csv')
head(races)
```

The races table contains the year and round number of the event, as does the fan rating column. Using this data along with the circuit_id value should be enough to get us fan scores broken down by each circuit. To keep our merge function simple, I'll create a new column in each table that contains the year and round number concatentated. This is the value I'll use to join the two tables together.

```{r join_data_circuitratings}
races$yr <- paste(races$year,races$round)
fan_ratings$yr <- paste(fan_ratings$Y, fan_ratings$R)
new_frame <- merge(x = fan_ratings, y = races, by="yr", all.x = TRUE)
new_frame <- new_frame[,c("year","round","circuitId","RATING")]
head(new_frame)
```

Now that all of the data has been joined into a single, useful table, I can aggregate the data to get an average race rating based on the circuit.

```{r summarize_circuitratings}
rating_by_circuit <- new_frame %>% group_by(circuitId) %>% summarize(mean_rating = mean(RATING))
rating_by_circuit <- merge(x = rating_by_circuit, y = circuits, by="circuitId", all.x = TRUE)
truncated_rating_bc <- rating_by_circuit[,c("name","mean_rating")]
truncated_rating_bc <- truncated_rating_bc[order(-truncated_rating_bc$mean_rating),]
print(truncated_rating_bc)
```

I now have the final table for the analysis of fan ratings by circuit. It appears that the Nurburgring has the highest average rating, while Magny-Cours has the loweset. At this point, I have realized that while my initial question was going to examine the impact the circuit length had on scores, I do not presently have that information available. I do believe that I can retrieve it, along with some information about weather, by scraping Wikipedia.

The next question I'll need to prepare data for is "How have rule changes in recent years impacted the quality of races?". I don't currently have data on rule changes, but these typically take place in between seasons. A summary of the average ratings of races by season will be sufficient for an initial analysis.

```{r load_data_fanratings}
rating_by_season <- fan_ratings %>% group_by(Y) %>% summarize(mean_rating = mean(RATING))

ggplot(rating_by_season, aes(Y,mean_rating)) + geom_line(color="blue", size=1) + geom_point() + scale_x_discrete(name="Year",limits=c(2008:2019)) + scale_y_continuous(name="Average Fan Rating", limits=c(0,10)) + ggtitle("Average Formula One Race Rating by Season") + labs(caption = "Fan Ratings compiled from user scores at Racefans.net")
print(rating_by_season)
```

The average ratings actually look pretty consistent from year to year. Based on these, we probably don't need to do further analysis on how the number of winners in a season impacts season ratings. The variance is too small for a meaningful impact.

The next thing to look at is how different teams and drivers impact the fan ratings.

```{r ratings_by_winning_driver}
rating_by_winner <- fan_ratings %>% group_by(P1) %>% summarize(mean_rating = mean(RATING))
print(rating_by_winner[order(rating_by_winner$mean_rating, decreasing=TRUE),])
```

It appears that there's a pretty significant variation in rating based on the winner. What about specific teams?

```{r ratings_by_team}
results <- read.csv('data/results.csv')
results <- results[results$positionOrder==1,]
constructors <- read.csv('data/constructors.csv')
results <- merge(x = results, y = constructors, by="constructorId", all.x = TRUE)
results <- merge(x = results, y = races, by="raceId", all.x = TRUE)
results <- merge(x = results, y = fan_ratings, by="yr", all.x = TRUE)
results <- results[complete.cases(results$RATING),]
rating_by_const <- results %>% group_by(name.x) %>% summarize(mean_rating = mean(RATING))
rating_by_const <- rating_by_const[complete.cases(rating_by_const),]
print(rating_by_const[order(rating_by_const$mean_rating , decreasing=TRUE),])
```

We can see a pretty big discrepancy in ratings between winning constructors as well.

```{r regression}
model <- lm(formula = RATING ~ name.x + P1 + GPNAME, data=results)
summary(model)
```

Looking at our summary of the model, we see only a few variables with significant p-values. Based on their coefficients, it appears that Brawn is a consistent detractor to ratings (Good thing they no longer exist!), Rubens Barichello was a solid boost to ratings (unfortunately he is retired), Valteri Bottas is bad for ratings, and Daniel Ricciardo is good for ratings. When it comes to grands prix the events with significant p-values all have positive coefficients. We can see this with Bahrain, Belgium, Brazil, the United Kingdom, Canada, and the United States. 